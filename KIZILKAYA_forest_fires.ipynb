{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KIZILKAYA_forest_fires.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BurakKizilkaya/Machine-Learning/blob/master/KIZILKAYA_forest_fires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "11NHh7SFlONx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNG 562 - HOMEWORK 1"
      ]
    },
    {
      "metadata": {
        "id": "oDePS7UGlNBQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question  : Forest Fires\n"
      ]
    },
    {
      "metadata": {
        "id": "ILOiCNxPI6bF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upload data(.csv file)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLwI4UCTUf4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import data\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"forestfires.csv\")\n",
        "\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HboO4wXZ0vA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating dummy variables for categorical columns\n",
        "data = pd.get_dummies(data, columns=['month', 'day'], drop_first=True)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Q_ACxs8J7ed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-fRr_o7h4f_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#making small fires(less than 100 m2) 0 others 1 according to http://www3.dsi.uminho.pt/pcortez/fires.pdf)\n",
        "data[data['area'] > 0 ] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QovgqZCxKD_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.columns, data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMdyLx78aZqY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#normalizing data\n",
        "import numpy as np\n",
        "\n",
        "tempx = np.array(data.drop('area', axis=1))\n",
        "tempy = np.array(data['area'])\n",
        "x = (tempx - tempx.min(0)) / tempx.ptp(0)\n",
        "y = (tempy - tempy.min(0)) / tempy.ptp(0)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_Ngxmq7KhHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.min(), x.max(), x.mean(axis=0), x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nT0wskjXavKL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split test and train data\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xea77RUZa3ot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Regression and Cross Validation\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4O3dFMdra2iF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#linear regression with sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "\n",
        "linreg = LinearRegression().fit(xtrain, ytrain)\n",
        "yscore = linreg.score(xtest,ytest)\n",
        "\n",
        "print(linreg.score(xtrain, ytrain))\n",
        "print(yscore)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vApSLmflciAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cross validation\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "lm = LinearRegression()\n",
        "\n",
        "scores = cross_val_score(lm, xtrain, ytrain, cv = 5)    #cv is the number of folds, scores will give an array of scores\n",
        "\n",
        "print(scores)\n",
        "print(np.mean(scores)) \n",
        "print(np.std(scores))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fzAT1jgDkfol",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decision Tree and Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "pbU5ifIVhdGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#decision tree with sklearn \n",
        "from sklearn.tree import DecisionTreeClassifier  \n",
        " \n",
        "dt = DecisionTreeClassifier()   \n",
        "dt.fit(xtrain, ytrain) \n",
        "\n",
        "ypred = dt.predict(xtest)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(ytest, ypred))\n",
        "print(\"Precision:\",metrics.precision_score(ytest, ypred))\n",
        "print(\"Recall:\",metrics.recall_score(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cmn8ISX7kO-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#grid search for decision tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "tuned_parameters = [{'criterion': ['gini', 'entropy'], 'max_features' : ['auto', 'log2', 1.0, 8, 0.66], 'min_samples_leaf' : [1, 2, 3]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
        "    clf.fit(xtrain, ytrain)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    ytrue, ypred = ytest, clf.predict(xtest)\n",
        "    print(classification_report(ytrue, ypred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MbZQ15vUkyP7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbour and Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "7ZrZkG-TkwTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#knn with sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier()\n",
        "neigh.fit(xtrain, ytrain) \n",
        "ypred = neigh.predict(xtest)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(ytest, ypred))\n",
        "print(\"Precision:\",metrics.precision_score(ytest, ypred))\n",
        "print(\"Recall:\",metrics.recall_score(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6dzBBYB9k7Co",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#grid search for support vector machine\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'n_neighbors': [3, 4, 5, 6, 7, 8, 9], 'weights' : ['uniform', 'distance']}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
        "    clf.fit(xtrain, ytrain)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    ytrue, ypred = ytest, clf.predict(xtest)\n",
        "    print(classification_report(ytrue, ypred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}