{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KIZILKAYA_adult_census_income.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LdUkHLplioYG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNG 562 - HOMEWORK 1"
      ]
    },
    {
      "metadata": {
        "id": "bx-nBpQei5aw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 1  : Adult Census Income\n"
      ]
    },
    {
      "metadata": {
        "id": "orlwuogCgVUv",
        "colab_type": "code",
        "outputId": "c10dbaf0-473f-43a8-c73c-4731f8c60cbc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "#importing json file which is downloaded from kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ba3e1732-bd6d-41fa-a8ac-acc27804c141\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ba3e1732-bd6d-41fa-a8ac-acc27804c141\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"burakkizilkaya\",\"key\":\"ee6f9dc9caf9bfd6f6082598e57c9f44\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "AdlkkmpggmAv",
        "colab_type": "code",
        "outputId": "21e509bf-4d44-44e3-a2aa-57f527115433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#if there is no kaggle directory, create a new one.\n",
        "!mkdir -p ~/.kaggle\n",
        "#copy kaggle.json file to kaggle directory\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#give owner read and write access permissions\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#check files in kaggle directory\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yATOxvyigvqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#install kaggle packages\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zMWKlU_vhF_f",
        "colab_type": "code",
        "outputId": "d8bb6614-3beb-48b9-805f-7deaf1182b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#download adult-census-income dataset\n",
        "!kaggle datasets download -d uciml/adult-census-income"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adult-census-income.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KJccNiA9hN4X",
        "colab_type": "code",
        "outputId": "af387496-161f-45f2-8898-de111135e2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#unzip downloaded dataset file\n",
        "!unzip adult-census-income.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  adult-census-income.zip\n",
            "replace adult.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: adult.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G755gPOAhU0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import data from .csv file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"adult.csv\")\n",
        "#data has ? symbol instead of NaN. Change them to NaN\n",
        "data = data.replace('?', np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtmXzGtRnHOv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Replace NaN values with mean for numeric columns\n",
        "for column in ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']:\n",
        "    data[column].fillna(data[column].mean(),inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XdG7jrS_zs64",
        "colab_type": "code",
        "outputId": "d1b54002-50a8-4792-e20f-6cd54a238430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "#Replace NaN values with mode for character columns\n",
        "for column in ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income']:\n",
        "    data[column].fillna(data[column].mode(),inplace=True)\n",
        "    \n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education.num</th>\n",
              "      <th>marital.status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital.gain</th>\n",
              "      <th>capital.loss</th>\n",
              "      <th>hours.per.week</th>\n",
              "      <th>native.country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>Private</td>\n",
              "      <td>77053</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>Private</td>\n",
              "      <td>132870</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>18</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66</td>\n",
              "      <td>NaN</td>\n",
              "      <td>186061</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54</td>\n",
              "      <td>Private</td>\n",
              "      <td>140359</td>\n",
              "      <td>7th-8th</td>\n",
              "      <td>4</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>3900</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>Private</td>\n",
              "      <td>264663</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Separated</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>3900</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
              "0   90   Private   77053       HS-grad              9        Widowed   \n",
              "1   82   Private  132870       HS-grad              9        Widowed   \n",
              "2   66       NaN  186061  Some-college             10        Widowed   \n",
              "3   54   Private  140359       7th-8th              4       Divorced   \n",
              "4   41   Private  264663  Some-college             10      Separated   \n",
              "\n",
              "          occupation   relationship   race     sex  capital.gain  \\\n",
              "0     Prof-specialty  Not-in-family  White  Female             0   \n",
              "1    Exec-managerial  Not-in-family  White  Female             0   \n",
              "2                NaN      Unmarried  Black  Female             0   \n",
              "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
              "4     Prof-specialty      Own-child  White  Female             0   \n",
              "\n",
              "   capital.loss  hours.per.week native.country income  \n",
              "0          4356              40  United-States  <=50K  \n",
              "1          4356              18  United-States  <=50K  \n",
              "2          4356              40  United-States  <=50K  \n",
              "3          3900              40  United-States  <=50K  \n",
              "4          3900              40  United-States  <=50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "aWmQB9X4kVCt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating dummy variables for categorical columns\n",
        "data = pd.get_dummies(data, columns=['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income'], drop_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2rHRPLMF_fyz",
        "colab_type": "code",
        "outputId": "409e0254-8d01-4fa1-f527-271476895560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "#normalizing data\n",
        "tempx = np.array(data.drop('income_>50K', axis=1))\n",
        "tempy = np.array(data['income_>50K'])\n",
        "x = (tempx - tempx.min(0)) / tempx.ptp(0)\n",
        "y = (tempy - tempy.min(0)) / tempy.ptp(0)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.04398745 0.53333333 ... 1.         0.         0.        ]\n",
            " [0.89041096 0.08189579 0.53333333 ... 1.         0.         0.        ]\n",
            " [0.67123288 0.11802067 0.6        ... 1.         0.         0.        ]\n",
            " ...\n",
            " [0.31506849 0.09650032 0.53333333 ... 1.         0.         0.        ]\n",
            " [0.56164384 0.09482688 0.53333333 ... 1.         0.         0.        ]\n",
            " [0.06849315 0.12849934 0.53333333 ... 1.         0.         0.        ]]\n",
            "[0. 0. 0. ... 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "stVCzcL6E2Zp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression and Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "cCdFxVHgD1b-",
        "colab_type": "code",
        "outputId": "635867e1-1a0b-4bfe-8f72-784c83c47b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#split test and train data\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25, random_state=0)\n",
        "\n",
        "#logistic regression with sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(xtrain, ytrain)\n",
        "ypred = logreg.predict(xtest)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(ytest, ypred))\n",
        "print(\"Precision:\",metrics.precision_score(ytest, ypred))\n",
        "print(\"Recall:\",metrics.recall_score(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8476845596364083\n",
            "Precision: 0.7298701298701299\n",
            "Recall: 0.5770020533880903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ioKW_H8NRMfk",
        "outputId": "ff5394f8-9e56-4e58-fff7-65eeeb4fe4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        }
      },
      "cell_type": "code",
      "source": [
        "#grid search for logistic regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "tuned_parameters = [{'solver': ['liblinear'], 'C': [1, 0.75, 0.5, 0.25, 0.1, 0.01], 'penalty': ['l1', 'l2']}]\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=5,\n",
        "                       scoring='%s_macro' % score)\n",
        "    clf.fit(xtrain, ytrain)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    ytrue, ypred = ytest, clf.predict(xtest)\n",
        "    print(classification_report(ytrue, ypred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.809 (+/-0.013) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.805 (+/-0.013) for {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.809 (+/-0.013) for {'C': 0.75, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.803 (+/-0.014) for {'C': 0.75, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.808 (+/-0.014) for {'C': 0.5, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.800 (+/-0.016) for {'C': 0.5, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.808 (+/-0.015) for {'C': 0.25, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.797 (+/-0.019) for {'C': 0.25, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.807 (+/-0.015) for {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.793 (+/-0.017) for {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.775 (+/-0.017) for {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.785 (+/-0.015) for {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.93      0.90      6193\n",
            "         1.0       0.73      0.58      0.65      1948\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      8141\n",
            "   macro avg       0.80      0.76      0.78      8141\n",
            "weighted avg       0.84      0.85      0.84      8141\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 0.75, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.765 (+/-0.022) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.758 (+/-0.019) for {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.765 (+/-0.022) for {'C': 0.75, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.757 (+/-0.019) for {'C': 0.75, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.765 (+/-0.022) for {'C': 0.5, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.753 (+/-0.019) for {'C': 0.5, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.762 (+/-0.022) for {'C': 0.25, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.748 (+/-0.022) for {'C': 0.25, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.757 (+/-0.021) for {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.740 (+/-0.019) for {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.707 (+/-0.014) for {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.714 (+/-0.014) for {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.93      0.90      6193\n",
            "         1.0       0.73      0.58      0.65      1948\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      8141\n",
            "   macro avg       0.80      0.76      0.78      8141\n",
            "weighted avg       0.84      0.85      0.84      8141\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CzrLGQBkYrXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decision Tree and Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "iL--0HYaYweX",
        "colab_type": "code",
        "outputId": "aba05741-efa0-4f36-e040-c6cb5281884f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#decision tree with sklearn \n",
        "from sklearn.tree import DecisionTreeClassifier  \n",
        " \n",
        "dt = DecisionTreeClassifier()   \n",
        "dt.fit(xtrain, ytrain) \n",
        "\n",
        "ypred = dt.predict(xtest)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(ytest, ypred))\n",
        "print(\"Precision:\",metrics.precision_score(ytest, ypred))\n",
        "print(\"Recall:\",metrics.recall_score(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8123080702616386\n",
            "Precision: 0.6074718526100307\n",
            "Recall: 0.6093429158110883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MbiMO_ZgZ9XQ",
        "colab_type": "code",
        "outputId": "0b280f66-0f28-474c-8153-ad7aeaa66c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        }
      },
      "cell_type": "code",
      "source": [
        "#grid search for decision tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "tuned_parameters = [{'criterion': ['gini', 'entropy'], 'max_features' : ['auto', 'log2', 1.0, 8, 0.66], 'min_samples_leaf' : [1, 2, 3]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
        "    clf.fit(xtrain, ytrain)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    ytrue, ypred = ytest, clf.predict(xtest)\n",
        "    print(classification_report(ytrue, ypred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 3}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.737 (+/-0.011) for {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 1}\n",
            "0.777 (+/-0.012) for {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 2}\n",
            "0.788 (+/-0.024) for {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 3}\n",
            "0.728 (+/-0.010) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 1}\n",
            "0.783 (+/-0.020) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 2}\n",
            "0.786 (+/-0.034) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 3}\n",
            "0.749 (+/-0.017) for {'criterion': 'gini', 'max_features': 1.0, 'min_samples_leaf': 1}\n",
            "0.760 (+/-0.016) for {'criterion': 'gini', 'max_features': 1.0, 'min_samples_leaf': 2}\n",
            "0.761 (+/-0.022) for {'criterion': 'gini', 'max_features': 1.0, 'min_samples_leaf': 3}\n",
            "0.733 (+/-0.020) for {'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 1}\n",
            "0.785 (+/-0.013) for {'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 2}\n",
            "0.782 (+/-0.029) for {'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 3}\n",
            "0.744 (+/-0.014) for {'criterion': 'gini', 'max_features': 0.66, 'min_samples_leaf': 1}\n",
            "0.761 (+/-0.009) for {'criterion': 'gini', 'max_features': 0.66, 'min_samples_leaf': 2}\n",
            "0.760 (+/-0.009) for {'criterion': 'gini', 'max_features': 0.66, 'min_samples_leaf': 3}\n",
            "0.740 (+/-0.005) for {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 1}\n",
            "0.778 (+/-0.007) for {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 2}\n",
            "0.792 (+/-0.003) for {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 3}\n",
            "0.730 (+/-0.013) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 1}\n",
            "0.784 (+/-0.014) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2}\n",
            "0.777 (+/-0.016) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 3}\n",
            "0.743 (+/-0.008) for {'criterion': 'entropy', 'max_features': 1.0, 'min_samples_leaf': 1}\n",
            "0.755 (+/-0.021) for {'criterion': 'entropy', 'max_features': 1.0, 'min_samples_leaf': 2}\n",
            "0.755 (+/-0.013) for {'criterion': 'entropy', 'max_features': 1.0, 'min_samples_leaf': 3}\n",
            "0.729 (+/-0.005) for {'criterion': 'entropy', 'max_features': 8, 'min_samples_leaf': 1}\n",
            "0.785 (+/-0.011) for {'criterion': 'entropy', 'max_features': 8, 'min_samples_leaf': 2}\n",
            "0.787 (+/-0.029) for {'criterion': 'entropy', 'max_features': 8, 'min_samples_leaf': 3}\n",
            "0.747 (+/-0.015) for {'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 1}\n",
            "0.756 (+/-0.004) for {'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 2}\n",
            "0.763 (+/-0.006) for {'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 3}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.94      0.90      6193\n",
            "         1.0       0.72      0.52      0.60      1948\n",
            "\n",
            "   micro avg       0.84      0.84      0.84      8141\n",
            "   macro avg       0.79      0.73      0.75      8141\n",
            "weighted avg       0.83      0.84      0.83      8141\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 3}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.743 (+/-0.018) for {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 1}\n",
            "0.737 (+/-0.008) for {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 2}\n",
            "0.746 (+/-0.029) for {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 3}\n",
            "0.732 (+/-0.016) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 1}\n",
            "0.733 (+/-0.026) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 2}\n",
            "0.734 (+/-0.020) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 3}\n",
            "0.752 (+/-0.021) for {'criterion': 'gini', 'max_features': 1.0, 'min_samples_leaf': 1}\n",
            "0.739 (+/-0.017) for {'criterion': 'gini', 'max_features': 1.0, 'min_samples_leaf': 2}\n",
            "0.751 (+/-0.022) for {'criterion': 'gini', 'max_features': 1.0, 'min_samples_leaf': 3}\n",
            "0.741 (+/-0.012) for {'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 1}\n",
            "0.741 (+/-0.021) for {'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 2}\n",
            "0.749 (+/-0.010) for {'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 3}\n",
            "0.750 (+/-0.015) for {'criterion': 'gini', 'max_features': 0.66, 'min_samples_leaf': 1}\n",
            "0.737 (+/-0.014) for {'criterion': 'gini', 'max_features': 0.66, 'min_samples_leaf': 2}\n",
            "0.747 (+/-0.021) for {'criterion': 'gini', 'max_features': 0.66, 'min_samples_leaf': 3}\n",
            "0.741 (+/-0.017) for {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 1}\n",
            "0.736 (+/-0.038) for {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 2}\n",
            "0.743 (+/-0.032) for {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 3}\n",
            "0.732 (+/-0.024) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 1}\n",
            "0.737 (+/-0.023) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2}\n",
            "0.704 (+/-0.041) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 3}\n",
            "0.748 (+/-0.013) for {'criterion': 'entropy', 'max_features': 1.0, 'min_samples_leaf': 1}\n",
            "0.740 (+/-0.022) for {'criterion': 'entropy', 'max_features': 1.0, 'min_samples_leaf': 2}\n",
            "0.751 (+/-0.025) for {'criterion': 'entropy', 'max_features': 1.0, 'min_samples_leaf': 3}\n",
            "0.735 (+/-0.017) for {'criterion': 'entropy', 'max_features': 8, 'min_samples_leaf': 1}\n",
            "0.739 (+/-0.021) for {'criterion': 'entropy', 'max_features': 8, 'min_samples_leaf': 2}\n",
            "0.751 (+/-0.031) for {'criterion': 'entropy', 'max_features': 8, 'min_samples_leaf': 3}\n",
            "0.752 (+/-0.019) for {'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 1}\n",
            "0.743 (+/-0.012) for {'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 2}\n",
            "0.754 (+/-0.016) for {'criterion': 'entropy', 'max_features': 0.66, 'min_samples_leaf': 3}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.89      0.88      6193\n",
            "         1.0       0.64      0.60      0.62      1948\n",
            "\n",
            "   micro avg       0.82      0.82      0.82      8141\n",
            "   macro avg       0.76      0.75      0.75      8141\n",
            "weighted avg       0.82      0.82      0.82      8141\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5z_ox7t4d9P3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machines and Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "wZb2Ca4deDne",
        "colab_type": "code",
        "outputId": "31e0c6c2-50d3-4b16-cb66-b49c81d026da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#support vector machine with sklearn\n",
        "from sklearn import svm\n",
        "\n",
        "supp = svm.SVC(gamma='scale')\n",
        "supp.fit(xtrain, ytrain)\n",
        "ypred = supp.predict(xtest)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(ytest, ypred))\n",
        "print(\"Precision:\",metrics.precision_score(ytest, ypred))\n",
        "print(\"Recall:\",metrics.recall_score(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8392089423903697\n",
            "Precision: 0.7274021352313167\n",
            "Recall: 0.5246406570841889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aroTVhKleqch",
        "colab_type": "code",
        "outputId": "eb51dd0f-c67a-4aac-d9c3-6617c487b1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1601
        }
      },
      "cell_type": "code",
      "source": [
        "#grid search for support vector machine\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
        "    clf.fit(xtrain, ytrain)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    ytrue, ypred = ytest, clf.predict(xtest)\n",
        "    print(classification_report(ytrue, ypred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.795 (+/-0.023) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.379 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.791 (+/-0.018) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.795 (+/-0.022) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.800 (+/-0.016) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.791 (+/-0.019) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.813 (+/-0.012) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.801 (+/-0.015) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.808 (+/-0.018) for {'C': 1, 'kernel': 'linear'}\n",
            "0.809 (+/-0.014) for {'C': 10, 'kernel': 'linear'}\n",
            "0.809 (+/-0.014) for {'C': 100, 'kernel': 'linear'}\n",
            "0.809 (+/-0.014) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.94      0.91      6193\n",
            "         1.0       0.76      0.55      0.64      1948\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      8141\n",
            "   macro avg       0.81      0.75      0.77      8141\n",
            "weighted avg       0.84      0.85      0.84      8141\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.680 (+/-0.015) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.722 (+/-0.016) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.680 (+/-0.015) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.739 (+/-0.018) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.722 (+/-0.016) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.752 (+/-0.016) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.741 (+/-0.018) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.754 (+/-0.024) for {'C': 1, 'kernel': 'linear'}\n",
            "0.757 (+/-0.020) for {'C': 10, 'kernel': 'linear'}\n",
            "0.757 (+/-0.020) for {'C': 100, 'kernel': 'linear'}\n",
            "0.757 (+/-0.019) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.94      0.90      6193\n",
            "         1.0       0.74      0.56      0.64      1948\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      8141\n",
            "   macro avg       0.81      0.75      0.77      8141\n",
            "weighted avg       0.84      0.85      0.84      8141\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R2_dhLKlhXnr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbour and Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "IFIos1lSg8qK",
        "colab_type": "code",
        "outputId": "c2c894d5-003f-4a58-f872-292651f2d5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#knn with sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier()\n",
        "neigh.fit(xtrain, ytrain) \n",
        "ypred = neigh.predict(xtest)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(ytest, ypred))\n",
        "print(\"Precision:\",metrics.precision_score(ytest, ypred))\n",
        "print(\"Recall:\",metrics.recall_score(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8248372435818695\n",
            "Precision: 0.6524532710280374\n",
            "Recall: 0.5734086242299795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pAdBj-7Whe8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#grid search for support vector machine\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'n_neighbors': [3, 4, 5, 6, 7, 8, 9], 'weights' : ['uniform', 'distance']}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
        "    clf.fit(xtrain, ytrain)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    ytrue, ypred = ytest, clf.predict(xtest)\n",
        "    print(classification_report(ytrue, ypred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}